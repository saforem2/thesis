\makeatletter
\def\input@path{{../}}
\makeatother
\documentclass[../main.tex]{subfiles}


\begin{document}
In recent years there has been an explosive growth in the fields of machine
learning (ML) and data science.
%
This trend has had a significant impact on a wide variety of industries and has
been used to produce incredible new technologies ranging from self-driving cars
to personalized recommendation engines and facial recognition software, to name
just a few.
% From self-driving cars to personalized recommendation engines and facial
% recognition,
% impacted a wide
% a trend that shows no signs of slowing down anytime soon.
%
Just as importantly, (but not as glamorously) many scientific researchers have
also begun looking for new ways to apply these ideas to their fields, producing
new interdisciplinary efforts and mutually-beneficial collaborations.
% leading to all
% new areas of interdisciplinary research
% resulting in
% many new cross-disciplinary efforts and collaborations.
%
% One field that stands to benefit tremedously from this new direction is computational physics, which relies heavily
% on data analysis and computer simulations

One field in particular that stands to benefit from this new direction is high
energy physics, which relies heavily on computational science through the use
of data analysis and computer simulations.
%
Historically, much of this work been done either through the use of
`brute-force' calculations, requiring tremendous computational resources, or
`by-hand' which tends to be pain-stakingly slow and is often subject to a whole
variety of potential issues (e.g.\ incomplete information, poor statistics,
incorrect models, unjustified approximations, human-error, etc.).
%
% In addition, with experiments such as the
%
Machine learning, on the other hand, aims to sidestep many of these problems
entirely by automatically `learning' information from data, and is capable of
discovering meaningful patterns that are oftentimes imperceivable to humans.
%
With projects such as the Large Hadron Collider at CERN producing roughly $15$
petabytes of data per year, the need for new and better methods for dealing
with this data continues to grow.
  
This thesis is primarily composed of the work completed during my graduate
career and includes some relevant background information that may be useful for
those looking to learn more information about how ideas from machine learning
can be applied to problems in lattice gauge theory and lattice quantum
chromodynamics (QCD).
%
In particular, Chapter~\ref{chap:machine_learning} provides a thorough
background on many of the machine learning tools used throughout the remainder
of the thesis and provides concrete examples on their use.
%
For example, topics such as such as supervised learning, gradient descent /
backpropagation, feed-forward and convolutional neural networks are covered.

Chapter~\ref{chap:unsupervised_learning} covers an example of how unsupervised
learning (specifically, principal component analysis) can be applied to extract
information about the phase transition of the two-dimensional Ising
model.
%
By representing equilibrium configurations of the system as two-dimensional
greyscale images, principal component analysis allows us to obtain a direct
relationship between the specific heat capacity and the eigenvalue of the
dominant principal component.
%
In Sec.~\ref{sec:trg} and Sec.~\ref{sec:rgimages}, a renormalization group
transformation is proposed that can be applied to generic sets of images, which
when applied to the images under consideration, leads to a finite-size scaling
analysis of the critical point.

In Chapter.~\ref{chap:mcmc}, a brief overview of Markov Chain Monte Carlo
(MCMC) methods in general is discussed, and relevant notation introduced.
% and the relevant notation used for the
% remainder of the is introduced.
%
% Sec.~\ref{sec:l2hmc_hmc}
In sections~\ref{subsec:mcmc_hamiltonian_dynamics},~\ref{sec:l2hmc_intro},
and~\ref{sec:l2hmc_u1}, some of the current problems faced by HMC are
discussed, particularly within the context of simulations in lattice gauge
theory and lattice QCD.

Chapter~\ref{chap:l2hmc} describes a new technique for applying supervised
learning to help improve the efficiency of Hamiltonian / Hybrid Monte Carlo
(HMC) simulations.
%
This new approach is called `Learning to Hamiltonian Monte Carlo' (L2HMC), and
is based off of the work described in~\cite{2017arXiv171109268L}.
%
%
The details of the L2HMC algorithm are presented in
Sec~\ref{sec:generalizing_lf}, and an example of this algorithm applied to a
two-dimensional Gaussian Mixture Model is included in Sec.~\ref{sec:l2hmc_gmm}.
%
Building on these results, we proceed to look at applying this approach to a
two-dimensional $U(1)$ lattice gauge theory, the details of which are laid-out
in Sec.~\ref{sec:l2hmc_u1}.
%
Finally, in
Sec.~\ref{subsec:l2hmc_modified_network}-~\ref{subsec:l2hmc_modifiedloss} we
discuss some of the modifications that were introduced when applying this
approach to the gauge model under consideration, and provide insight into why
these modifications were both necessary and advantageous.
\end{document}
