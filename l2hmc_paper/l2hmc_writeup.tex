\makeatletter
\def\input@path{{../}}
\makeatother
\documentclass[../main.tex]{subfiles}


\newcommand{\lfop}{\mathbf{L}_{\theta}}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}%
\label{sec:l2hmc_intro}
%
We describe a new technique for performing Hamiltonian Monte-Carlo (HMC)
simulations called: `Learning to Hamiltonian Monte Carlo'
(L2HMC)~\cite{2017arXiv171109268L} which expands upon the traditional HMC by
using a generalized version of the leapfrog integrator that is parameterized by
weights in a neural network.
%
In order to demonstrate the usefulness of this new approach, we use various
metrics for measuring the performance of the trained (L2HMC) sampler vs.\ the
generic HMC sampler.

First, we will look at applying this algorithm to a two-dimensional Gaussian
Mixture Model (GMM).
%
The GMM is a notoriously difficult distribution for HMC due to the vanishingly
small likelihood of the leapfrog integrator traversing the space between the
two modes.
%
Conversely, we see that through the use of a carefully chosen training
procedure, the trained L2HMC sampler is able to successfully discover the
existence of both modes, and mixes (`tunnels') between the two with ease. 
%
Additionally, we will observe that the trained L2HMC sampler mixes much faster
than the generic HMC sampler, as evidenced through their respective
autocorrelation spectra.

This ability to reduce autocorrelations is an important metric for measuring
the efficiency of a general MCMC algorithm, and is of great importance for
simulations in lattice gauge theory and lattice QCD.
%
Following this, we introduce the two-dimensional $U(1)$ lattice gauge theory
and describe important modifications to the algorithm that are of particular
relevance for lattice models.
%
Ongoing issues and potential areas for improvement are also discussed,
particularly within the context of high-performance computing and long-term
goals of the lattice QCD community.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Generalizing the Leapfrog Integrator}
\label{sec:generalizing_lf}
As in the previously described HMC algorithm, we start by augmenting the
current state $x \in \mathbb{R}^n$ with a continuous momentum variable $v \in
\mathbb{R}^{n}$ drawn from a standard normal distribution.
%
Additionally, we introduce a binary direction variable $d \in \{ -1, 1\}$,
drawn from a uniform distribution. 
%
The complete augmented state is then denoted by $\xi \equiv (x, v, d)$, with
probability density $p(\xi) = p(x) p(v)
p(d)$.
%
% In order to improve our model's ability to accurately describe more complicated
% In order to improve the expressivity (i.e.\ performance on
% We can improve our models performance by introducing a fixed random binary mask
% $m^{t} \in \{0, 1\}$ that
To improve the overall performance of our model, for each step $t$ of the
leapfrog operator $\mathbf{L}_{\theta}$, we assign a fixed random binary mask
$m^{t} \in{\{0, 1\}}^n$ that will determine which variables are affected by
each sub-update.
%
The mask $m^t$ is drawn uniformly from the set of binary vectors satisfying
$\sum_{i=1}^{n} m_{i}^{t} = \lfloor \frac{n}{2}\rfloor$, i.e.\ half the entries
of $m^t$ are $0$ and half are $1$.
%
Additionally, we write $\bar m^{t} = \mathbbm{1} - m^{t}$ and $x_{m^t} = x
\odot m^{t}$, where $\odot$ denotes element-wise multiplication, and
$\mathbbm{1}$ the vector of $1$'s in each entry.
%

We begin with a subset of the augmented space, $\zeta_1 \equiv (x, \partial_{x}
U(x), t)$, independent of the momentum $v$.
%
We introduce three new functions of $\zeta_1$: $T_v$, $Q_v$, and $S_v$.
%
We can then perform a single time-step of our modified leapfrog integrator
$\mathbf{L}_{\theta}$.
%

First, we update the momentum $v$, which depends only on the subset $\zeta_1$.
%
This update is written
%
\begin{equation}
  \vp = v\, \odot%
      \hspace{-1mm}%
      \underbrace{\exp\left(\frac{\varepsilon}{2}
      S_{v}(\zeta_1)\right)}_{\text{%
        \footnotesize{\textbf{Momentum scaling}\normalsize}
      }}%
        \hspace{-1mm}%
      - \frac{\varepsilon}{2}\bigg[%
          \partial_{x} U(x)%
          \odot\hspace{-1mm}\underbrace{\exp(\varepsilon
          Q_{v}(\zeta_1))}_{\text{%
            \footnotesize{\textbf{Gradient scaling}\normalsize}
          }}
        + \underbrace{T_v(\zeta_1)}_{\text{%
            \footnotesize{\textbf{Translation}\normalsize}
          }}
      \bigg]
  % \vp = v \odot
  %   \underbrace{\exp\left(\frac{\varepsilon}{2}
  %   S_{v}(\zeta_1)\right)}_{\text{\footnotesize{Momentum scaling}}}%
  %   - \frac{\varepsilon}{2}\left[\partial_{x} U(x)%
  %     \odot\underbrace{\exp(\varepsilon
  %     Q_{v}(\zeta_1))}_{\text{\footnotesize{Gradient scaling}}}%
  %   + \underbrace{T_v(\zeta_1)}_{\text{\footnotesize{Translation}}}\right].
    \label{eq:update_momentum_forward1}
\end{equation}
%
and the corresponding Jacobian is given by:
$\exp{\left(\frac{\eps}{2}\mathbbm{1} \cdot S_{v}(\zeta_1)\right)}$.
%
Next, we update $x$ by first updating a subset of the coordinates of $x$
(determined according to the mask $m^t$), followed by the complementary subset
(determined from $\bar m^{t}$).
%
The first update affects only $x_{m^{t}}$ and produces $x^{\prime}$.
%
This update depends only on the subset $\zeta_2 \equiv (x_{\bar m^t}, v, t)$.
%
Following this, we perform the second update which only affects
$x_{\bar{m}^t}^{\prime}$ and depends only on $\zeta_3 \equiv (x_{m^t}^{\prime},
v, t)$, to produce $x^{\prime\prime}$:
%
\begin{align}
  x^{\prime} &= x_{\bar{m}^t} + m^{t}\odot\left[x \odot \exp{(\eps
      S_x(\zeta_2))} + \eps\left(v^{\prime}\odot%
    \exp{(\eps Q_x(\zeta_2))} + T_x(\zeta_2)\right)\right]\\
  x^{\prime\prime} &= x^{\prime}_{m^t} + \bar m^t \odot \left[x^{\prime} \odot
    \exp{(\eps S_x(\zeta_3))} +%
    \eps\left(v^{\prime} \odot \exp{(\eps Q_x(\zeta_3))} +
  T_x(\zeta_3)\right)\right].
\end{align}
%
with Jacobians: $\exp{(\eps m^{t} \cdot S_x(\zeta_2))}$, and
$\exp{(\eps\bar{m^t}\cdot S_x(\zeta_3))}$, respectively. 
%
Finally, we proceed to update $v$ again, using the subset $\zeta_4 \equiv
(x^{\prime\prime}, \partial_{x} U^{\prime\prime}, t)$: 
%
\begin{equation} 
  \vpp = \vp \odot \exp\left(\frac{\varepsilon}{2} S_v(\zeta_4)\right) -
    \frac{\varepsilon}{2}\left[\partial_{x} U
  \odot \exp(\varepsilon Q_v(\zeta_4)) + T_v(\zeta_4)\right].
    \label{eq:update_momentum_forward2}
\end{equation}
%
In order to build some intuition about each of these terms, we discuss below
some of the subtleties contained in this approach and how they are (carefully)
dealt with.

The first thing to notice about these equations is that if $S_{i} = Q_{i} =
T_{i} = 0$ ($i = x, v$), we recover the previous equations for the generic
leapfrog integrator (as we would expect since we are attempting to
\emph{generalize} HMC).
%
We can also see a similarity between the equations for updating $v$ and those
for updating $x$: each update is generalized by \emph{scaling} the previous
value ($v$ or $x$), and \emph{scaling and translating} the updating value
(either $\partial_{x}\,U(x)$ or $x$).
%
It can be shown~\cite{2017arXiv171109268L}, that the scaling applied to the
momentum in Eq~\ref{eq:update_momentum_forward1} can enable, among other
things, acceleration in low-density zones to facilitate mixing between modes,
and that the scaling term applied to the gradient may allow better conditioning
of the energy landscape (e.g., by learning a diagonal inertia tensor), or
partial ignoring of the energy gradient for rapidly oscillating energies.

Second, note that because the determinant of the Jacobian appears in the
Metropolis-Hastings (MH) acceptance probability, we require the Jacobian of
each update to be efficiently computable (i.e.\ independent of the variable
actually being updated).
%
For each of the momentum updates, the input is a subset $\zeta = (x,
\partial_{x}\,U(x), t)$ of the augmented space and the associated Jacobian is
$\exp{\left(\frac{\eps}{2}\mathbbm{1}\cdot S_{v}(\zeta)\right)}$ which is
independent of $v$ as desired.
%
For the position updates however, things are complicated by the fact that the
input $\zeta$ is $x$-dependent.
%
In order to ensure that the Jacobian of the $x$ update is efficiently
computable, it is necessary to break the update into two parts following the
approach outlined in \emph{Real-valued Non-Volume Preserving transformations
(RealNVP)}~\cite{dinhRealNVP}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Metropolis-Hastings Accept/Reject}
%
Written in terms of these transformations, the augmented leapfrog operator
$\mathbf{L}_{\theta}$ consists of $M$ sequential applications of the
single-step leapfrog operator $\mathbf{L}_{\theta} \xi = \mathbf{L}_{\theta}(x,
v, d) = (x^{\prime\prime\times M}, v^{\prime\prime\times M}, d)$, followed by
the previously-defined momentum flip operator $\mathbf{F}$ which flips the
direction variable $d$, i.e.\ $\mathbf{F}\xi = (x, v, -d)$.
%
Using these, we can express a complete molecular dynamics update step as
$\mathbf{FL}_{\theta}\xi = \xip$, where now the Metropolis-Hastings acceptance
probability for this proposal is given by
%
\begin{equation}
    A(\mathbf{F}\mathbf{L} \xi | \xi) = \min\left(1,
        \frac{p(\mathbf{F}\mathbf{L}\xi)}{p(\xi)}\left|
        \frac{\partial\left[\mathbf{F}\mathbf{L}\xi\right]}
            {\partial\xi^{T}}\right|\right),
\end{equation}
%
Where $\left|\frac{\partial\left[\mathbf{F}\mathbf{L}\xi\right]}
{\partial\xi^{T}}\right|$ denotes the determinant of the Jacobian describing
the transformation.

In contrast to generic HMC where
$\left|\frac{\partial\left[\mathbf{F}\mathbf{L}\xi\right]}
{\partial\xi^{T}}\right| = 1$, we now have non-symplectic transformations
(i.e.\ non-volume preserving) and so we must explicitly account for the
determinant of the Jacobian.
%
These non-volume preserving transformations have the effect of deforming the
energy landscape, which, depending on the nature of the transformation, may
allow for the exploration of regions of space which were previously
inaccessible.
%
\newcommand{\energyA}{\includegraphics[width=0.4\textwidth]{energy_landscape/original_energy_landscape.pdf}}
\newcommand{\energyB}{\includegraphics[width=0.4\textwidth]{energy_landscape/modified_energy_landscape.pdf}}
%
\begin{figure}
  \centering 
  \Huge
  \parbox{\widthof{\energyA}}{\energyA} $\overset{\mathcal{J}}{\longrightarrow}$
  \parbox{\widthof{\energyB}}{\energyB} 
  \normalsize
  \caption{Example of how the determinant of the Jacobian can deform the energy landscape.}
\end{figure}

To simplify our notation, introduce an additional operator $\mathbf{R}$ that
re-samples the momentum and direction, e.g.\ given $\xi = (x, v, d)$,
$\mathbf{R}\,\xi = (x, v^{\prime}, d^{\prime})$ where $v^{\prime} \sim
\mathcal{N}(0, I)$, $d^{\prime} \sim \mathcal{U}\left(\{-1, 1\}\right)$.
%
A complete sampling step of our algorithm then consists of the following two
steps:
%
\begin{enumerate}
    \item $\xi^{\prime} = \mathbf{FL}_{\theta} \,\xi$ with probability
        $A(\mathbf{FL}_{\theta}\,\xi|\xi)$ (Eq.~\ref{eq:metropolis_hastings}),
        otherwise $\xi^{\prime} = \xi$.
    \item $\xi^{\prime} = \mathbf{R}\,\xi$.
\end{enumerate}
%
Note however, that for MH to be well-defined, this deterministic operator must
be \emph{invertible} and \emph{have a tractable Jacobian} (i.e.\ we can compute
its determinant).
%
In order to make this operator invertible, we augment the state space $(x, v)$
into $(x, v, d)$, where $d \in \{-1, 1\}$ is drawn with equal probability and
represent the direction of the update.
%
All of the previous expressions for the augmented leapfrog updates represent
the forward ($d = 1$) direction.
%
We can derive the expressions for the backward direction ($d = -1$) by
reversing the order of the updates (i.e.\ $\vpp \rightarrow \vp$, then $\xpp
\rightarrow \xp$, followed by $\xp \rightarrow x$ and finally $\vp \rightarrow
v$).
%
For completeness, we include in Sec.~\ref{sec:lf_forward} and
Sec~\ref{sec:lf_backward} all of the equations (both forward and backward
directions) relevant for updating the variables of interest in our augmented
leapfrog sampler.

%
% \clearpage
% \subsection{Augmented Leapfrog Equations}%
% \label{subsec:augmented_leapfrog_equations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Forward Direction \texorpdfstring{$(d = 1)$}{(d = 1)}:}%
\label{sec:lf_forward}
% \vspace{-20pt}
\begin{align}
  \vp &= v \odot \exp{\left(\frac{\eps}{2}S_{v}(\zeta_{1})\right)}% 
        - \frac{\eps}{2}\left[\partial_{x}\,U(x)\odot \exp{\left(\eps
          Q_{v}(\zeta_{1})\right)}%
        + T_{v}(\zeta_{1})\right] \\
  \xp &= x_{\bar{m}^{t}} + m^{t}\odot \left[x \odot \exp{\left(\eps
    S_{x}(\zeta_{2})\right)}%
        + \eps\left(\vp\odot\exp{\left(\eps Q_{x}(\zeta_{2})\right)} 
          + T_{x}(\zeta_{2})\right)\right] \\
  \xpp &= x^{\prime}_{m^{t}} + \bar{m}^{t}\odot \left[\xp \odot \exp{\left(\eps
    S_{x}(\zeta_{3})\right)}%
        + \eps\left(\vp\odot\exp{\left(\eps Q_{x}(\zeta_{3})\right)} +
      T_{x}(\zeta_{3})\right)\right] \\
  \vpp &= \vp \odot \exp{\left(\frac{\eps}{2}S_{v}(\zeta_{4})\right)}%
        - \frac{\eps}{2}\left[\partial_{x}\,U(\xpp)\odot \exp{\left(\eps
          Q_{v}(\zeta_{4})\right)}%
          + T_{v}(\zeta_{4})\right]
\end{align} 
%
With $\zeta_{1} = (x, \partial_{x}\, U(x), t)$, $\zeta_{2} = (x_{\bar{m}^{t}},
v, t)$, $\zeta_{3} = (x^{\prime}_{m^{t}}, v, t)$, $\zeta_{4} = (\xpp,
\partial_{x}\, U(\xpp), t)$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Backward Direction \texorpdfstring{$(d = -1)$}{(d = -1)}:}%
\label{sec:lf_backward}
%
\begin{align}
  v^{\prime} &= {\left\{v + \frac{\eps}{2}\left[\partial_{x}\,U(x)\odot
        \exp{\left(\eps Q_{v}(\zeta_{1})\right)}%
    + T_{v}(\zeta_{1})\right]\right\}} \odot
    \exp{\left(-\frac{\eps}{2}S_{v}(\zeta_{1})\right)} \\
  \xp &= x_{m^{t}} + \bar{m}^{t}\odot%
    {\left[x - \eps{\left(\exp{\left(\eps Q_{x}(\zeta_{2})\right)}\odot \vp%
    + T_{x}(\zeta_{2})\right)}\right]}\odot \exp{\left(-\eps
    S_{x}(\zeta_{2})\right)} \\ 
  \xpp &= x_{\bar{m}^{t}} + m^{t}\odot%
    {\left[\xp - \eps{\left(\exp{\left(\eps Q_{x}(\zeta_{3})\right)}\odot \vp%
    + T_{x}(\zeta_{3})\right)}\right]}\odot \exp{\left(-\eps
    S_{x}(\zeta_{3})\right)} \\
  v^{\prime\prime} &= {\left\{\vp +
      \frac{\eps}{2}\left[\partial_{x}\,U(\xpp)\odot%
        \exp{\left(\eps Q_{v}(\zeta_{1})\right)}
  + T_{v}(\zeta_{1})\right]\right\}}\odot 
    \exp{\left(-\frac{\eps}{2}S_{v}(\zeta_{4})\right)}
\end{align}
%
With $\zeta_{1} = (x, \partial_{x}\, U(x), t)$, $\zeta_{2} = (x_{m^{t}}, v,
t)$, $\zeta_{3} = (x^{\prime}_{\bar{m}^{t}}, v, t)$, $\zeta_{4} = (\xpp,
\partial_{x}\, U(\xpp), t)$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Determinant of the Jacobian}
In terms of the auxiliary functions $S_{i}, Q_{i}, T_{i}$, we can compute the
Jacobian:
%
\begin{align}
  \log|\mathcal{J}| 
  &= \log\bigg|\frac{\partial{\left[\mathbf{FL}_{\theta}\xi\right]}}{\partial
  \xi^{T}}\bigg|\\
  &= d \sum_{t\leq N_{\mathrm{LF}}}
    {\left[\frac{\eps}{2} \mathbbm{1}\cdot S_{v}(\zeta_{1}^{t}) + \eps m^{t}
        \cdot S_{x}(\zeta_{2}^{t}) 
      + \eps \bar{m}^{t} \cdot S_{x}(\zeta_{3}^{t}) + \frac{\eps}{2}\mathbbm{1}
\cdot S_{v}(\zeta_{4}^{t})\right]}.  \end{align}
%
where $N_{\mathrm{LF}}$ is the number of leapfrog steps, and $\zeta_{i}^{t}$
denotes the intermediary variable $\zeta_{i}^{t}$ at time step $t$ and $d$ is
the direction of $\xi$, i.e.\ $d = 1 \,\, (-1)$ for the forward (backward)
update.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Network Architecture}%
\label{subsec:l2hmc_network}
As previously mentioned, each of the functions $Q$, $S$, and $T$, are
implemented using multi-layer perceptrons with shared weights.
%
It's important to note that we keep separate the network responsible for
paramterizing the functions used in the position updates (`$\Xnet$', i.e.\
$Q_x$, $S_x$, and $T_x$), and the network responsible for parameterizing the
momentum updates (`$\Vnet$', i.e.\ $Q_v$, $S_v$, and $T_v$).
%
Since both networks are identical, we describe the architecture of $\Vnet$
below, and include a flowchart for $\Xnet$ illustrative purposes in
Fig~\ref{fig:x_net_flowchart}.
%
%
\begin{figure}[htpb]
  \centering
  \includegraphics[width=\textwidth]{generic_net/generic_net4.png}
  \caption{Illustration showing the generic (fully-connected) network
    architecture for training $S_v$, $Q_v$, and $T_v$. Figure adapted
		with permission from~\cite{joeyl2hmc}.}%
\label{fig:generic_net}
\end{figure}
%

The network takes as input $\zeta_1 = (x, \partial_{x} U(x), t)$, where $x, v
\in \mathbb{R}^{n}$, and $t$ is encoded as $\tau(t) = \left(\cos{(\frac{2\pi
t}{N_{\mathrm{LF}}})},\right.  \left.\sin{(\frac{2\pi
t}{N_{\mathrm{LF}}})}\right)$.
%
Each of the inputs is then passed through a fully-connected (`dense' layer),
consisting of $n_h$ hidden units
%
\begin{align}
    \tilde x &= W^{(x)} x + b^{(x)} \quad (\in \mathbb{R}^{n_h})\\
    \tilde v &= W^{(v)} v + b^{(v)} \quad (\in \mathbb{R}^{n_h})\\
    \tilde \tau &= W^{(\tau)} \tau + b^{(\tau)} \quad (\in \mathbb{R}^{n_h}).
\end{align}
%
Where $W^{(x)}, W^{(v)} \in \mathbb{R}^{n \times n_h}$, $W^{(t)} \in
\mathbb{R}^{2 \times n_h}$, and $b^{(x)}$, $b^{(v)}$,  $b^{(t)} \in
\mathbb{R}^{n_h}$.
%
From these, the network computes
%
\begin{equation}
    h_1 = \sigma(\tilde x + \tilde v + \tilde \tau) \quad (\in
    \mathbb{R}^{n_h}).
    \label{eq:hidden_1}
\end{equation}
%
Where $\sigma(x) = \max(0, x)$ denotes the rectified linear unit (ReLU)
activation function.
%
Next, the network computes
%
\begin{equation}
    h_2 = \sigma\left(W^{(h_1)} h_1 + b^{(h_1)}\right) \quad (\in
    \mathbb{R}^{n_h}).
    \label{eq:hidden_2}
\end{equation}
%
These weights ($h_2$) are then used to compute the network's output:
%
\begin{align}
    S_x &= \lambda_S \tanh(W^{(S)} h_2 + b^{(S)})\quad (\in \mathbb{R}^{n})\\
    Q_x &= \lambda_{Q} \tanh(W^{(Q)} h_2 + b^{(Q)})\quad (\in \mathbb{R}^{n})\\
    T_x &= W^{(T)} h_2 + b^{(T)}\quad (\in \mathbb{R}^{n}),
\end{align}
%
Where $W^{(s)}, W^{(q)}$, and $W^{(T)} \in \mathbb{R}^{n_h \times n}$ and
$b^{(s)}, b^{(q)}$, and $b^{(T)} \in \mathbb{R}^{n}$.
%
The parameters $\lambda_s$ and $\lambda_q$ are additional trainable variables
initialized to zero.
%
The network used for parameterizing the functions $T_v$, $Q_v$ and $S_v$ takes
as input $(x, \partial_x U(x), t)$ where again $t$ is encoded as above.  The
architecture of this network is the same, and produces outputs $T_v$, $Q_v$,
and $S_v$.

\begin{figure}[htpb]
  \centering
  \includegraphics[width=\textwidth]{generic_net/x_net_flowchart4.png}
  \caption{Flowchart illustrating the generic fully-connected network
    architecture including the intermediate variables computed at each hidden
    layer of the network.}%
\label{fig:x_net_flowchart}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Training Procedure}
%
By augmenting traditional HMC methods with these trainable functions, we hope
to obtain a sampler that has the following key properties:
%
\begin{enumerate}
    \item Fast mixing (i.e.\ able to quickly produce uncorrelated samples).
    \item Fast burn-in (i.e.\ rapid convergence to the target distribution).
    \item Ability to mix across energy levels.
    \item Ability to mix between modes.
\end{enumerate}
%
Following the results in~\cite{10.2307/24308995}, we design a loss function
with the goal of maximizing the expected squared jumped distance (or
analogously, minimizing the lag-one autocorrelation).
%
To do this, we first introduce 
\begin{equation}
  \delta(\xi, \xip) = \delta((x^{\prime}, v^{\prime}, d^{\prime}), (x, v, d))
  \equiv \| x - x^{\prime}\|^2_2.  \label{eq:metric_orig}
\end{equation}
%
Then, the expected squared jumped distance is given by $\mathbb{E}_{\xi\sim
p(\xi)} \left[\delta(\mathbf{FL}_{\theta}\xi, \xi) A(\mathbf{FL}_{\theta}\xi |
\xi)\right]$.
%
By maximizing this objective function, we are encouraging transitions that
efficiently explore a local region of state-space, but may fail to explore
regions where very little mixing occurs.
%
To help combat this effect, we define a loss function
%
\begin{equation}
    \ell_{\lambda}(\xi, \xi^{\prime}, A(\xi^{\prime}|\xi)) =
        \frac{\lambda^2}{\delta(\xi,\xi^{\prime}) A(\xi^{\prime}|\xi)} -
        \frac{\delta(\xi,\xi^{\prime}) A(\xi^{\prime}|\xi)}{\lambda^2}
    \label{eq:loss_ell}
\end{equation}
%
where $\lambda$ is a scale parameter describing the characteristic length scale
of the problem.
%
Note that the first term helps to prevent the sampler from becoming stuck in a
state where it cannot move effectively, and the second term helps to maximize
the distance between subsequent moves in the Markov chain.  

The sampler is then trained by minimizing $\ell_{\lambda}$ over both the target
and initialization distributions.
%
Explicitly, for an initial distribution $\pi_0$ over $\mathcal{X}$, we define
the initialization distribution as $q(\xi) = \pi_0(x) \mathcal{N}(v; 0, I)
p(d)$, and minimize
%
\begin{equation}
    \mathcal{L}(\theta)\equiv \mathbb{E}_{p(\xi)}\left[\ell_{\lambda}(\xi,
    \mathbf{FL}_{\theta}\xi, A(\mathbf{FL}_{\theta}\xi|\xi))\right] + \lambda_b
    \mathbb{E}_{q(\xi)}\left[\ell_{\lambda}(\xi, \mathbf{FL}_{\theta}\xi,
    A(\mathbf{FL}_{\theta} \xi| \xi))\right].
    \label{eq:loss_L}
\end{equation}
%
For completeness, we include the full algorithm~\cite{2017arXiv171109268L} used
to train L2HMC in Alg.~\ref{alg:l2hmc}.
%
\begin{algorithm}[htbp]%
  % \centering
    \SetKwProg{Fn}{def}{\string:}{}%
    \SetKwFunction{Range}{range}%
    \SetKwFor{For}{for}{\string:}{}%
    \SetKwIF{If}{ElseIf}{Else}{if}{:}{elif}{else:}{}%
    \SetKwFor{While}{while}{:}{fintq}%
    \AlgoDontDisplayBlockMarkers\SetAlgoNoEnd%
    % \SetAlgoNoLine%
    \DontPrintSemicolon%
    \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}%
    \caption{Training procedure for the L2HMC algorithm.}%
    \Input{%
      \vspace{-5pt}
      \begin{enumerate}
        \item A (potential) energy function, $U: \mathcal{X} \rightarrow
          \mathbb{R}$ and its gradient $\nabla_x U: \mathcal{X} \rightarrow
          \mathcal{X}$\
          \vspace{-10pt}
        \item Initial distribution over the augmented state space, $q$
          \vspace{-10pt}
        \item Number of iterations, $N_{\mathrm{train}}$
          \vspace{-10pt}
        \item Number of leapfrog steps, $N_{\mathrm{LF}}$
          \vspace{-10pt}
        \item Learning rate schedule, ${(\alpha_{t})}_{t\leq N_{\text{train}}}$
          \vspace{-10pt}
        \item Batch size, $N_{\mathrm{samples}}$
          \vspace{-10pt}
        \item Scale parameter, $\lambda$
          \vspace{-10pt}
        \item Regularization strength, $\lambda_b$
      \end{enumerate}
    }\;
    \vspace{-15pt}
    Initialize the parameters of the sampler, $\theta$\;
    Initialize ${\{\xi_{p^{(i)}}\}}_{i\leq N_{\mathrm{samples}}}$ from
    $q{(\xi)}$\; \For{$t = 0$ \KwTo\ $N_{\mathrm{train}}$}{%
      Sample a minibatch, ${\left\{\xi_{q}^{(i)}\right\}}_{i\leq
      N_{\mathrm{samples}}}$ from $q{(\xi)}$.\; $\mathcal{L}\leftarrow 0$\;
      \For{$i = 1$ \KwTo$N_{\mathrm{LF}}$} {%
          $\xi_{p}^{(i)} \leftarrow\ \mathbf{R}\,\xi_p^{(i)}$\;
          $\mathcal{L} \,\,\,\,\leftarrow\mathcal{L} +
          \ell_{\lambda}\left(\xi_p^{(i)}, \FLq\xi_p^{(i)}, A
            (\FLq\xi^{(i)}_p|\xi^{(i)}_p)\right) + \lambda_b
            \ell_{\lambda}\left(\xi^{(i)}_q, \FLq\xi^{(i)}_q,
            A (\FLq\xi^{(i)}_q|\xi^{(i)}_q)\right)$\;
          $\xi_p^{(i)} \leftarrow \FLq\xi^{(i)}_p$ with probability
        $A(\FLq\xi^{(i)}_p|\xi^{(i)}_p)$\; }%
      \vspace{2pt}
      $\theta\ \leftarrow\ \theta-\alpha_t \nabla_{\theta} \mathcal{L}$\;
    }%
\label{alg:l2hmc}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Gaussian Mixture Model}%
\label{sec:l2hmc_gmm}
%
The Gaussian Mixture Model (GMM) is a notoriously difficult example for
traditional HMC to sample accurately due to the existence of multiple modes.
%
In particular, HMC cannot mix between modes that are reasonably separated
without recourse to additional tricks.
%
This is due, in part, to the fact that HMC cannot easily traverse the
low-density zones which exist between modes.

In the most general case, we consider a target distribution described by a
mixture of $M > 1$ components in
$\mathbb{R}^{D}$ for $D \geq 1$:
%
\begin{equation}
    p(\mathbf{x}) \equiv \sum_{m=1}^{M} p(m) p(\mathbf{x}|m) \equiv
        \sum_{m=1}^{M} \pi_m p(\mathbf{x}|m) \quad \forall \,\,\mathbf{x} \in
        \mathbb{R}^{D}
    \label{eq:gmm_model}
\end{equation}
%
where $\sum_{m=1}^{M} \pi_m = 1$, $\pi_M \in (0, 1)$ $\forall m = 1, \ldots, M$
and each component distribution is a normal probability distribution in
$\mathbb{R}^{D}$.
%
So $\mathbf{x}|m \sim \mathcal{N}(\bm{\mu}_m, \bm{\Sigma}_m)$, where
$\bm{\mu}_m \equiv \mathbb{E}_{p{(\mathbf{x}|m)}}\left\{\mathbf{x}\right\}$ and
$\mathbf{\Sigma}_m \equiv \mathbb{E}_{p{(\mathbf{x}|m)}}{\left\{{(\mathbf{x} -
\bm{\mu}_m)}{(\mathbf{x} - \bm{\mu}_m)}^{T}\right\}} > 0$ are the mean vector
and covariance matrix, respectively, of component $m$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example}
%
Consider a simple 2D case consisting of two Gaussians 
%
\begin{equation}
    \mathbf{x} \sim \pi_1 \,\mathcal{N}(\bm{\mu}_1, \bm{\Sigma}_1) +
        \pi_2\, \mathcal{N}(\bm{\mu}_2, \bm{\Sigma}_2)
    \label{eq:log_likelihood_example}
\end{equation}
%
with $\pi_1 = \pi_2 = 0.5$, $\bm{\mu}_1 = (-2, 0)$, $\bm{\mu}_2 = (2, 0)$ and
%
\begin{equation}
    \bm{\Sigma}_1 = \bm{\Sigma}_2 = 
        \begin{bmatrix}
            0.1    & 0 \\
            0       & 0.1 
        \end{bmatrix}
    \label{eq:covariance_matrix}
\end{equation}
%
The results of trajectories generated using both traditional HMC and the L2HMC
algorithm can be seen in Fig.~\ref{fig:gmm_trajectories}.
a
Note that traditional HMC performs poorly and is unable to mix between the two
modes, whereas L2HMC is able to correctly sample from the target distribution
without getting stuck in either of the individual modes.

%
The L2HMC sampler was trained using simulated annealing using the schedule
shown in Eq~\ref{eq:gmm_annealing} with a starting temperature of $T = 10$, for
$5,000$ training steps.
%
By starting with a high temperature, the chain is able to move between both
modes (`tunnel') successfully.
%
Once it has learned this, we can lower the temperature back to $T = 1$ and
recover the initial distribution while preserving information about tunneling
in the networks ``memory''.
%
\begin{equation}
  T(n) = {\left(T_{i} - T_{f}\right)} \cdot {\left(1 -
  \frac{n}{N_{\mathrm{train}}}\right)} + T_{f} 
\label{eq:gmm_annealing}
\end{equation}
%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{gmm_figures/iso_gmm_chains1}
    \caption{Comparison of trajectories generated using L2HMC (top), and
        traditional HMC with $\eps = 0.25$ (middle) and $\eps = 0.5$ (bottom).
        Note that L2HMC is able to successfully mix between modes, whereas HMC
        is not.}%
\label{fig:gmm_trajectories}
\end{figure}
%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.98\textwidth]{gmm_figures/gmm_acl}
    \caption{Autocorrelation vs.\ gradient evaluations (i.e.\ MD steps). Note
    that L2HMC (blue) has a significantly reduced autocorrelation after the
  same number of gradient evaluations when compared to either of the two HMC
trajectories}% 
\label{fig:gmm_autocorrelation} 
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{2D \texorpdfstring{$U(1)$}{U (1)} Lattice Gauge Theory}%
\label{sec:l2hmc_u1} 
All lattice QCD simulations are performed at finite
lattice spacing $a$ and need an extrapolation to the continuum in order to be
used for computing values of physical quantities.
%
More reliable extrapolations can be done by simulating the theory at
increasingly smaller lattice spacings.
%
The picture that results when the lattice spacing is reduced and the physics
kept constant is that all finite physical quantities of negative mass dimension
diverge if measured in lattice units.
%
In statistical mechanics language, this states that the continuum limit is a
critical point of the theory since correlation lengths diverge.
%
MCMC algorithms are known to encounter difficulties when used for simulating
theories close to a critical point, an issue known as the \emph{critical slowing
down} of the algorithm.
%
This effect is most prominent in the topological charge, whose auto-correlation
time increases dramatically with finer lattice spacings.
%
As a result, there is a growing interest in developing new sampling techniques
for generating equilibrium configurations. 
%
In particular, algorithms that are able to offer improvements in efficiency
through a reduction of statistical autocorrelations are highly desired. 
%
We begin with the two-dimensional $U{(1)}$ lattice gauge theory with dynamical
variables $U_{\mu}{(i)}$ defined on the links of a lattice, where $i$ labels a
site and $\mu$ specifies the direction.
%
Each link $U_{\mu}{(i)}$ can be expressed in terms of an angle $-\pi <
\phi_{\mu}{(i)} \leq \pi$.
%
\begin{equation}
    U_{\mu}{(i)} = e^{i\phi_{\mu}{(i)}}
    \label{eq:link_variable}
\end{equation}
%
with the Wilson action defined as:
%
\begin{equation}
    \beta S = \beta \sum_{P}{(1 - \cos{(\phi_{P})})}
    \label{eq:wilson_action}
\end{equation}
%
where
%
\begin{equation}
    \phi_{P} \equiv \phi_{\mu\nu}(i) = 
        \phi_{\mu}{(i)} + \phi_{\nu}{(i + \hat{\mu})} 
        - \phi_{\mu}{(i + \hat{\nu})} - \phi_{\nu}{(i)}
    \label{eq:phi_plaquette}
\end{equation}
%theta_
and $\beta = 1/e^{2}$ is the gauge coupling, and the sum $\sum_{P}$ runs over
all plaquettes of the lattice.
%
An illustration showing how these variables are defined for an elementary
plaquette is shown in Fig.~\ref{fig:plaquette}.
%
\begin{figure}[htpb]
  \centering
  \includegraphics[width=0.5\textwidth]{gauge_figures/plaquette.png}
  \caption{Illustration of an elementary plaquette on the lattice.}%
\label{fig:plaquette}
\end{figure}

We can define the topological charge, $Q \in \mathbb{Z}$, as
%
\begin{equation}
  Q \equiv \frac{1}{2\pi}\sum_{P} \tilde \phi_{P} =
    \frac{1}{2\pi}\sum_{\substack{{i; \mu, \nu}\\{\nu > \mu}}}
    \tilde \phi_{\mu\nu}{(i)}
    \label{eq:topological_charge}
\end{equation}
%
where
%
\begin{equation}
  \tilde{\phi}_{P} \equiv \phi_{P} - 2\pi {\bigg\lfloor{\frac{\phi_{P} +
  \pi}{2\pi}\bigg\rfloor}}
  % \tilde{\phi}_{P} \equiv \phi_{P} - 2 \pi \left \lfloor{\frac{\phi_{P} +
  % \pi}{2 \pi}\right \rfloor}
\end{equation}
%
is the sum of the link variables around the elementary plaquette, projected
onto the interval $\left[-\pi, \pi\right)$.
%
From this, we can define topological susceptibility
%
\begin{equation}
    \chi \equiv \frac{\langle Q^2\rangle - \langle Q \rangle^2}{V}
    % \label{eq:topological_susceptibility}
\end{equation}
%
By parity symmetry, $\langle Q \rangle = 0$, so we have that
\begin{equation}
    \chi = \frac{\langle Q^2\rangle}{V}
    \label{eq:topological_susceptibility}
\end{equation}
%
Unfortunately, the measurement of $\chi$ is often difficult due to the fact
that the autocorrelation time with respect to $Q$ tends to be extremely long.
%
This is a consequence of the fact that the Markov chain tends to get stuck in a
topological sector (characterized by $Q = const$.), a phenomenon known as
\emph{topological freezing}.
%
\begin{figure}[htpb]
  \centering
    % \includegraphics[width=0.49\textwidth]{top_charge_vs_step_hmc.eps}
    % \includegraphics[width=0.49\textwidth]{top_charge_vs_step_l2hmc.eps}
    \includegraphics[width=0.49\textwidth]{charge_plots/compare/top_charge_vs_step_hmc}
    \includegraphics[width=0.49\textwidth]{charge_plots/compare/top_charge_vs_step_l2hmc}
    \caption{(left) Example of topological freezing in the $2D$ $U{(1)}$
      lattice gauge theory, generated from generic HMC sampling for a
      $16\times16$ lattice. Note that for the majority of the simulation
      $Q=-2$, making it virtually impossible to get a reasonable estimate of
  $\chi$.  (right) Topological charge vs.\ step generated using the trained
  L2HMC sampler.}\label{fig:top_charge} \end{figure}
%
\subsection{Modified Network Architecture}%
\label{subsec:l2hmc_modified_network}
%
In order to better account for the rectangular geometry of the lattice, a stack
of convolutional layers was prepended to the existing architecture, and can be
seen in Fig.~\ref{fig:conv_net}. The output from this convolutional structure
is then fed to the generic network shown in Fig.~\ref{fig:generic_net}.
%
\begin{figure}[htpb] 
  \centering
  \includegraphics[width=\textwidth]{conv_net/conv_net_final.png}
  % \includegraphics[width=\textwidth]{full_network/generic_net.png}
  \caption{Convolutional structure used for learning localized features of
  rectangular lattice.}% 
\label{fig:conv_net} 
\end{figure}
% \vspace{-40pt}
%
\begin{figure}[htpb] 
  \centering
  \includegraphics[width=0.95\textwidth]{conv_net/vnet_hq.png}
  \caption{Illustration taken from TensorBoard showing an overview of the
  network architecture for VNet. Note that the architecture is identical for
XNet.} \vspace{12pt}
\includegraphics[width=0.95\textwidth]{conv_net/vnet_zoom_hq.png}
\caption{Detailed view of additional convolutional structure included to better
account for rectangular geometry of lattice inputs.} \end{figure}
%
Additionally, the network architecture was modified to include a batch
normalization layer after the second MaxPool layer.
%
Introducing batch normalization is a commonly used technique in practice, and
is known to help prevent against diverging gradients\footnote{a numerical issue
in which infinite values are generated when calculating the gradients in
backpropagation}, (an issue that was occasionally encountered during the
training procedure).
%
Additionally, it has been shown to improve model performance and generally
requires fewer training steps to achieve similar performance as models trained
without it~\cite{Ioffe_Szegedy_2015}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Annealing Schedule}% 
\label{subsec:l2hmc_u1annealing}
% In addition to modifying the neural network architecture, we also modified
% the training algorithm to follow a simulated annealing schedule.
%
Proceeding as in the example of the Gaussian Mixture Model, we include a
simulated annealing schedule in which the value of the gauge coupling $\beta$
is continuously updated according to the annealing schedule shown in
Eq.~\ref{eq:annealing_schedule}.
%
% Explicitly, the value of the gauge coupling $\beta$ is continuously updated
% according to the annealing schedule shown in Eq.~\ref{eq:annealing_schedule}.
%
This was done in order to encourage sampling from multiple different
topological charge sectors, since our sampler is less `restricted' at lower
values of $\beta$.
%This was don
\begin{equation} 
  \frac{1}{\beta(n)} = {\left(\frac{1}{\beta_{i}} 
    - \frac{1}{\beta_{f}}\right)}
    {\left(\frac{1 - n}{N_{\mathrm{train}}}\right)} 
    + \frac{1}{\beta_{f}} 
\label{eq:annealing_schedule} 
\end{equation}
%
Here $\beta(n)$ denotes the value of $\beta$ to be used for the
$n^{\mathrm{th}}$ training step ($n = 1, \ldots, N_{\mathrm{train}}$),
$\beta_{i}$ represents the initial value of $\beta$ at the beginning of the
training, and $\beta_{f}$ represents the final value of $\beta$ at the end of
training.
%
For a typical training session, $N_{\mathrm{train}} = 25,000$, $\beta_{i} = 2$
and $\beta_{f} = 5$.
% For all of the exmaples above, $N_{\mathrm{train}} = 25,000$, $\beta_{0} = 2$
% and $\beta_{N_{\mathrm{train}}} = 5$.
%
% As can be seen in Fig.~\ref{fig:top_charge}

% \section{UPDATES (04/08/2019)}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Modified Loss Function for \texorpdfstring{$U(1)$}{U (1)} Gauge
Model}%
\label{subsec:l2hmc_modifiedloss}
%
In order to more accurately define the ``distance'' between two different
lattice configurations, we redefine the metric in Eq.~\ref{eq:metric_orig} to
be
%
\begin{equation}
  % \delta(\xi(\phi_{\mu}(x)), \xip(\phi_{\mu}(x))) \equiv 1 -
  % \cos\left(\xi(\phi_{\mu}(x)) - \xi^{\prime}(\phi_{\mu}(x))\right)
  \delta(\xi, \xip) \equiv 1 - \cos\left(\xi - \xi^{\prime}\right)
\label{eq:metric_new}
\end{equation}
%
where now $\xi \equiv {\left(\phi_{\mu}^{x}(i), \,\phi_{\mu}^{v}(i),\,
d\right)}$, with $\phi_{\mu}^{x}$ representing the lattice of (`position')
gauge variables (what we called $x$ previously), and $\phi_{\mu}^{v}$
representing the lattice of (`momentum') gauge variables (what we called $v$
previously). Note that $i$ runs over all lattice sites\footnote{In what
  follows, we will refrain from explicitly including the site index and make
  the assumption that it implicitly extends over all sites on the lattice.} and
  $\mu=0, 1$ for the two dimensional case.
%
We see that this metric gives the expected behavior, since $\delta \rightarrow
0$ for $\xi \approx \xip$.

While this new metric helps to better measure distances in this configuration
space, it does nothing to encourage the exploration of different topological
sectors since there may be configurations for which $\delta(\xi, \xip) \approx
1$ but $Q(\xi) = Q(\xip)$.
%
In order to potentially address this issue, we modify the original loss
function as follows.


First define $\xip\equiv \FLq \xi$ as the resultant configuration proposed by
the augmented leapfrog integrator, and
%
\begin{align}
  \delta_{Q}{(\xi, \xi^{\prime})} &= \left|Q{(\xi)} - Q{(\xi^{\prime})}\right| \\
  \ell_{Q}{\left(\xi, \xip, A{(\FLq\xi|\xi)}\right)} &= \delta_{Q}{(\xi,\xip)}
    \times A{(\xip|\xi)}.
\end{align}
%
So we have that $\delta_{Q}$ measures the difference in topological charge
between the initial and proposed configurations, and $\ell_{Q}$ gives the
expected topological charge difference.
%
Proceeding as before, we include an additional auxiliary term which is
identical in structure to the one above, except the input is now a
configuration of link variables $\phi_{\mu}$ drawn from the initialization
distribution $q$, which for our purposes was chosen to be the standard random
normal distribution on $[0, 2\pi)$. %]

We can then write the topological loss term as
%
\begin{equation}
  \mathcal{L}_{Q}(\theta) \equiv
    \mathbb{E}_{p(\xi)}{\left[\ell_{Q}{\left(\xi,
      \FLq \xi, A{(\FLq\xi|\xi)}\right)}\right]}
      + \alpha_{\mathrm{aux}}\, \mathbb{E}_{q(\xi)}{\left[\ell_{Q}{\left(\xi,
      \FLq \xi, A{(\FLq\xi|\xi)}\right)}\right]}
      \label{eq:topological_loss_term1}
\end{equation}
%
If we denote the standard loss (with the modified metric function) defined in
Eq.~\ref{eq:loss_L} as $\mathcal{L}_{\mathrm{std}}{(\theta)}$, we can write the
new total loss as a combination of these two terms,
%
\begin{equation}
  \mathcal{L}(\theta) =
    \alpha_{\mathrm{std}}\, \mathcal{L}_{\mathrm{std}}(\theta) 
    + \alpha_{Q}\, \mathcal{L}_{Q}(\theta)
    \label{eq:topological_loss_term}
\end{equation}
%
where $\alpha_{\mathrm{std}}, \alpha_Q$ are multiplicative factors that weigh
the relative contributions to the total loss from the standard and topological
loss terms respectively, and $\alpha_{\mathrm{aux}}$ in
Eq.~\ref{eq:topological_loss_term1} weighs the contribution of configurations
drawn from the initialization distribution.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Issues with the Average Plaquette}
%
Upon further testing, an issue was encountered in which the average plaquette
$\langle \phi_{P}\rangle$ seems to converge to a value which is noticeably
different from the expected value in the infinite volume limit.
%
This behavior can be seen in Fig.~\ref{fig:bad_convergence}, and seems to
depend on both the number of augmented leapfrog steps used by our integrator,
as well as the `strength' of the topological loss term in
Eq.~\ref{eq:topological_loss_term}.
%
The parameters used in Fig~\ref{fig:bad_convergence} are as follows: $L = 8$,
$N_{\mathrm{LF}} = 7$, $\alpha_{Q} = 0.5$, and $N_{\mathrm{samples}} = 128$,
$N_{\mathrm{train}} = 1\times10^{4}$.
%
In Fig~\ref{fig:good_convergence}, the only change was the weight factor for the topological charge term in the loss
function $\alpha_{Q} = 0$.
%
\begin{figure}[htpb]%
  \centering
    \includegraphics[width=0.49\textwidth]{plaq_plots/plaqs_vs_step_bad.pdf}
    \includegraphics[width=0.49\textwidth]{plaq_plots/plaqs_diffs_vs_step_bad.pdf}
    \caption{\textbf{(left)}: Average plaquette $\langle\phi_{P}\rangle$ vs.\
      step for $L=8$, $N_{\mathrm{LF}} = 7$, and $\alpha_{Q} = 0.5$. Here the
      solid red line indicates the true value of the average plaquette (in the
      infinite volume limit, and is equal to $0.89338\ldots$
      \textbf{(right)}: Difference between the observed and expected value of
      the average plaquette $\delta_{\phi_{P}}$ vs.\ step.  Note that
    $\delta_{\phi_{P}} \neq 0$.}%
\label{fig:bad_convergence}
\end{figure}
\begin{figure}[htpb]%
  \vspace{-20pt}
  \centering
    \includegraphics[width=0.49\textwidth]{plaq_plots/plaqs_vs_step_good.pdf}
    \includegraphics[width=0.49\textwidth]{plaq_plots/plaqs_diffs_vs_step_good.pdf}
    \caption{Same quantities as in Fig~\ref{fig:bad_convergence}, with
    $\alpha_{Q} = 0$. Note that the discrepancy $\delta_{\phi_{P}}$ is no
  longer present.}
\label{fig:good_convergence}
\end{figure}
%
In order to quantify this unexpected behavior, we can calculate the difference
between the observed value of the average plaquette, $\langle \phi_{P}\rangle$
and the expected value $\phi_{P}^{(*)}$:
% 
\begin{equation}
  {\delta_{\phi_P}}(\alpha_Q, N_{\mathrm{LF}}) \equiv \langle \phi_P\rangle -
  \phi_{P}^{(*)} \neq 0
  % - \langle{\phi_{P}^{\mathrm{(exact)}}}\rangle \neq 0}.
\end{equation}
%
Which allows us to measure the severity of this discrepancy.%

Initially it was believed that this behavior was due to the topological charge
term in the loss function, however after testing using $\alpha_{Q} = 0$, this
behavior was still present.
%
Following this initial test, it was discovered that the discrepancy seemed to
be more prevalent when using a larger number of leapfrog steps
$N_{\mathrm{LF}}$.
%
In an additional systematic attempt to debug the problem, the sampler was
trained and evaluated multiple times over a range of different values of both
$N_{\mathrm{LF}}$ and $\alpha_{Q}$.
%
These results are included in Appendix~\ref{chap:debugging_results}.
%
Frustratingly, the issue seemed to be almost irreproducible.
%
Running the training/evaluation processes multiple times using the exact same
set of initial parameters on the exact same hardware it was observed that
sometimes the discrepancy was present while other times it was not.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}%
\label{sec:l2hmc_conclusion}
In conclusion, we have seen how the Hamiltonian Monte Carlo algorithm follows
from the Metropolis-Hastings algorithm used in generic Markov Chain Monte Carlo
methods, and why this approach is often preferred when attempting to sample
from the high-dimensional distributions characteristic of lattice gauge theory
models.

% as well as the possible benefits and downsides of MCMC methods are defined
% and used in practice to
Following this, a detailed description of the Hamiltonian Monte Carlo algorithm
was presented, as well as some of the
common issues faced when it is applied to lattice quantum chromodynamics.
%
In order to address some of these issues, we then proceeded to introduce a
learned inference architecture that
successfully generalized HMC by augmenting the traditional leapfrog integrator
with a set of carefully-chosen functions which are parameterized by weights in
a neural network.
%
This system is then trained to learn a MCMC kernel that encourages fast mixing
and convergence to the target distribution.
%
While this transition kernel is no longer symplectic, we are able to retain the
strong theoretical guarantee of HMC by enforcing a tractable MH accept/reject
step, making L2HMC potentially capable of sampling from very challenging
distributions.
%
Having introduced the necessary background, we then looked at applying this
algorithm to the notoriously difficult two-dimensional Gaussian mixture model.
%
In doing so, we found that the trained L2HMC sampler was capable of
successfully mixing between modes in a way that traditional HMC was not.
%
Additionally, we looked at the autocorrelation spectra of samples generated
from the trained L2HMC sampler compared to those obtained from HMC.
%
It was observed that the L2HMC sampler was able to produce samples which were
noticeably less correlated in far fewer steps, indicating that the L2HMC
algorithm significantly outperforms traditional HMC.
%
In lattice QCD simulations, the ability of a sampler to quickly produce
uncorrelated samples is one of the most important metrics for measuring its
efficiency, and the approach outlined in this chapter shows promise in reducing
the amount of computational resources required to generate new lattice
configurations. 

%
It remains to be seen how this algorithm performs when applied to more
complicated models (e.g.\ models with fermions and non-Abelian gauge theories),
a direction I plan to investigate more carefully in future research.
%
The other, seemingly non-fundamental issue with this approach is the
discrepancy between the observed and expected value of the average plaquette.
%
As of now, I am inclined to believe that this is more of a `bug' than an
inherent problem with the algorithm itself.

MCMC methods have proven to be indispensable in exploring new physics beyond
what can be achieved analytically, and has significantly advanced our
understanding of quantum field theory and quantum chromodynamics.
%
Unfortunately, in order to both perform and  extract meaningful results from
these simulations, tremendous amounts of computational resources are required,
with cutting-edge simulations being carried out almost exclusively on some of
the worlds largest supercomputers.
%
Because of this, even minor improvements in efficiency can dramatically reduce
the amount of computational power
required, allowing for increasingly complex models to be studied.
%
The pursuit of better, more efficient algorithms is one of the major long-term
goals of the lattice community, and is
directly aligned with many of the goals outlined for high energy physics in the
era of exascale computing. 
%
In particular, the results of these simulations are of central importance to
the experiments being carried out at the
Relativistic Heavy Ion Collider at Brookhaven National Laboratory (BNL), and
the Large Hadron Collider (LHC) at CERN.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
